{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from urllib import urlopen\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urllib.urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "#X = [feature(d) for d in data]\n",
    "#y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))\n",
    "\n",
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "#X_train = X\n",
    "#y_train = y\n",
    "\n",
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam,X,X_train,y_train):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n",
    "\n",
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta,X,y_train):\n",
    "  scores = [inner(theta,x) for x in X]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "  correct = [(a==b) for (a,b) in zip(predictions,y_train)]\n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc\n",
    "\n",
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "\n",
    "#lam = 1.0\n",
    "\n",
    "#theta = train(lam)\n",
    "#acc = performance(theta)\n",
    "#print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fa97296a657b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'beer/ABV'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m6.5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperformance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"valid acc: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-77c048dcb9f2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(lam, X, X_train, y_train)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m   \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpgtol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Khor_000\\Anaconda2\\lib\\site-packages\\scipy\\optimize\\lbfgsb.pyc\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 193\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    194\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    195\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Khor_000\\Anaconda2\\lib\\site-packages\\scipy\\optimize\\lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Khor_000\\Anaconda2\\lib\\site-packages\\scipy\\optimize\\lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-77c048dcb9f2>\u001b[0m in \u001b[0;36mfprime\u001b[1;34m(theta, X, y, lam)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mdl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlam\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;31m#X_train = X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "print \"Question 1:\"\n",
    "X_train = [feature(d) for d in data[:len(data)/3] ]\n",
    "X_valid = [feature(d) for d in data[len(data)/3:(len(data)*2)/3] ]\n",
    "X_test = [feature(d) for d in data[(len(data)*2)/3:] ]\n",
    "y_train = [d['beer/ABV'] >= 6.5 for d in data[:len(data)/3]]\n",
    "y_valid = [d['beer/ABV'] >= 6.5 for d in data[len(data)/3:(len(data)*2)/3]]\n",
    "y_test = [d['beer/ABV'] >= 6.5 for d in data[(len(data)*2)/3:]]\n",
    "lam = 1.0\n",
    "theta = train(lam,X_train,X_train,y_train)\n",
    "acc = performance(theta,X_valid,y_valid)\n",
    "print \"valid acc: \", acc\n",
    "acc = performance(theta,X_test,y_test)\n",
    "print \"test acc: \", acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Question 2:\" \n",
    "print 'feature function'\n",
    "print ''\n",
    "\n",
    "import re\n",
    "\n",
    "def wc(key,rv):\n",
    "    tt = re.compile('\\w+').findall(rv.lower())\n",
    "    return tt.count(key)\n",
    "\n",
    "def Q2feature(datum):\n",
    "    rv = datum['review/text']\n",
    "    return [1,wc('lactic',rv),wc('tart',rv),\n",
    "    wc('sour',rv),wc('citric',rv),wc('sweet',rv),\n",
    "    wc('acid',rv),wc('hop',rv),wc('fruit',rv),wc('salt',rv),wc('spicy',rv)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print 'Question 3:'\n",
    "FN = float(0)\n",
    "TN = float(0)\n",
    "TP = float(0)\n",
    "FP = float(0)\n",
    "X_train = [Q2feature(d) for d in data[:len(data)/3] ]\n",
    "y_train = [d['beer/ABV'] >= 6.5 for d in data[:len(data)/3]]\n",
    "X_test = [Q2feature(d) for d in data[(len(data)*2)/3:] ]\n",
    "y_test = [d['beer/ABV'] >= 6.5 for d in data[(len(data)*2)/3:]]\n",
    "lam = 1.0\n",
    "theta = train(lam,X_train,X_train,y_train)\n",
    "scores = [inner(theta,x) for x in X_test]\n",
    "predictions = [s > 0 for s in scores]\n",
    "for (p,r) in zip(predictions,y_test):\n",
    "    if p and r:\n",
    "        TP +=1 \n",
    "    elif p == 1 and r == 0:\n",
    "        FP +=1\n",
    "    elif p == 0 and r==1:\n",
    "        FN += 1\n",
    "    elif p == 0 and r == 0:\n",
    "        TN+=1\n",
    "BER =  0.5*(FP/(TN+FP) + FN/(FN+TP))\n",
    "print 'TN:',TN\n",
    "print 'TP:',TP\n",
    "print 'FN:',FN\n",
    "print 'FP:',FP\n",
    "print 'balanced error rate: ', BER\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Question 4:'\n",
    "print 'Used features in Question2'\n",
    "lams = [0,0.01,0.1,1,100]\n",
    "X_train  = [Q2feature(d) for d in data[:len(data)/3]]\n",
    "y_train = [d['beer/ABV'] >= 6.5 for d in data[:len(data)/3]]\n",
    "X_valid = [Q2feature(d) for d in data[len(data)/3:(len(data)*2)/3]]\n",
    "y_valid = [d['beer/ABV'] >= 6.5 for d in data[len(data)/3:(len(data)*2)/3]]\n",
    "X_test = [Q2feature(d) for d in data[(len(data)*2)/3:]]\n",
    "y_test = [d['beer/ABV'] >= 6.5 for d in data[(len(data)*2)/3:]]\n",
    "bestacc = 0\n",
    "lam = None\n",
    "for lam in lams:\n",
    "    print 'lam = ', lam\n",
    "    theta = train(lam,X_train,X_train,y_train)\n",
    "    tracc = performance(theta,X_train,y_train)\n",
    "    print 'acc on train:', tracc\n",
    "    vacc = performance(theta,X_valid,y_valid)\n",
    "    print 'acc on valid:', vacc\n",
    "    teacc = performance(theta,X_test,y_test)\n",
    "    print 'acc on test:', teacc\n",
    "    print '----------------------------------------------------'\n",
    "    if bestacc < vacc:\n",
    "        bestacc = vacc    \n",
    "        bestlam = lam\n",
    "print 'best lamda: ', bestlam\n",
    "acc = performance(theta,X_train,y_train)\n",
    "print 'acc on train:', acc\n",
    "print 'acc on valid:', bestacc\n",
    "acc = performance(theta,X_test,y_test)\n",
    "print 'acc on test:', acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "\n",
    "print \"Question 5:\"\n",
    "X_train  = [Q2feature(d)[1:] for d in data[:len(data)/3]]\n",
    "y_train = [d['beer/ABV'] >= 6.5 for d in data[:len(data)/3]]\n",
    "X_valid = [Q2feature(d)[1:] for d in data[len(data)/3:(len(data)*2)/3]]\n",
    "y_valid = [d['beer/ABV'] >= 6.5 for d in data[len(data)/3:(len(data)*2)/3]]\n",
    "X_test = [Q2feature(d)[1:] for d in data[(len(data)*2)/3:]]\n",
    "y_test = [d['beer/ABV'] >= 6.5 for d in data[(len(data)*2)/3:]]\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)\n",
    "print 'PCA components on train set:'\n",
    "print pca.components_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Question 6:'\n",
    "print np.matmul(X_train[0],(pca.components_).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Question 7:'\n",
    "pcavar = pca.explained_variance_\n",
    "print \"Reconstruction error of d = 2:\"\n",
    "print 'covariance Matrix eig val: ', sum(pcavar[2:])*len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print 'Question 8:'\n",
    "y = np.matmul(X_train,pca.components_[:2].T)\n",
    "xipa = list()\n",
    "yipa = list()\n",
    "xoth = list()\n",
    "yoth = list()\n",
    "for i in range(len(y)):\n",
    "    if data[i]['beer/style'] == 'American IPA':\n",
    "        xipa.append(y[i][0])\n",
    "        yipa.append(y[i][1])\n",
    "    else:\n",
    "        xoth.append(y[i][0])\n",
    "        yoth.append(y[i][1])\n",
    "plt.scatter(xoth,yoth,color= 'blue')        \n",
    "plt.scatter(xipa,yipa,color= 'red')\n",
    "#plt.scatter(xipa,yipa,color= 'red');\n",
    "plt.title('first two features (IPA = red, others = blue)')\n",
    "plt.xlabel('feature1')\n",
    "plt.ylabel('feature2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
